{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPCLibriSpeech.model_management import build_models\n",
    "from CPCLibriSpeech.data_management import get_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "from options import opt\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "# 10 speakers, 10 samples per session\n",
    "# Gives seg-fault:\n",
    "# py test.py ./models/1635417953561\n",
    "\n",
    "test_dev = opt[\"test_dev\"]\n",
    "batch_size = opt[\"test_batch_size\"]\n",
    "num_workers = opt[\"num_workers\"]\n",
    "tsne_spk_frac = opt[\"tsne_spk_frac\"]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    model_dir = str(sys.argv[1])\n",
    "\n",
    "    model = build_models.CPC_LibriSpeech_Encoder()\n",
    "    model.load_state_dict(torch.load(\n",
    "        model_dir + \"/best_model_params\", map_location=\"cpu\"))\n",
    "    model = model.to(test_dev)\n",
    "\n",
    "    test_speakers = json.load(open(model_dir + \"/test_speakers.txt\"))\n",
    "    # debug_fraction = 0.1\n",
    "    # random.sample(test_speakers,len(test_speakers*debug_fraction))\n",
    "    test_p = [s for S in test_speakers for s in glob.glob(S + \"**/*.flac\")]\n",
    "\n",
    "    dataset = get_data.LibriSpeechDataset(test_p)\n",
    "    test_dataset = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=False)\n",
    "\n",
    "    try:\n",
    "        c_data = pkl.load(open(model_dir + \"c_data.pkl\", \"rb\"))\n",
    "        e_data = pkl.load(open(model_dir + \"e_data.pkl\", \"rb\"))\n",
    "        m_data = pkl.load(open(model_dir + \"m_data.pkl\", \"rb\"))\n",
    "    except:\n",
    "        c_data = []\n",
    "        e_data = []\n",
    "        m_data = []\n",
    "        with torch.no_grad():\n",
    "            for B, spk, rec, sess, chk in tqdm(test_dataset):\n",
    "                B = B.float().to(test_dev)\n",
    "                C, E = model.encodings(B)\n",
    "                spk = copy.deepcopy(spk)\n",
    "                for sp, c, e in zip(spk.to(\"cpu\").detach().numpy(), C.to(\"cpu\").detach().numpy(), E.to(\"cpu\").detach().numpy()):\n",
    "                    c_data.append(c[-1])\n",
    "                    e_data.append(e[-1])\n",
    "                    m_data.append(sp)\n",
    "                del B\n",
    "                del spk\n",
    "                del chk\n",
    "        c_data = np.array(c_data)\n",
    "        e_data = np.array(e_data)\n",
    "\n",
    "        pkl.dump(c_data, open(model_dir + \"c_data.pkl\", \"wb\"))\n",
    "        pkl.dump(e_data, open(model_dir + \"e_data.pkl\", \"wb\"))\n",
    "        pkl.dump(m_data, open(model_dir + \"m_data.pkl\", \"wb\"))\n",
    "\n",
    "    data_len = len(c_data)\n",
    "    test_frac = int(.1*data_len)\n",
    "\n",
    "    c_data = np.array(c_data)\n",
    "    e_data = np.array(e_data)\n",
    "    lr_target = np.array(m_data)\n",
    "\n",
    "    c_lr = LogisticRegression()\n",
    "    c_lr.fit(c_data[:test_frac], lr_target[:test_frac])\n",
    "    e_lr = LogisticRegression()\n",
    "    e_lr.fit(e_data[:test_frac], lr_target[:test_frac])\n",
    "\n",
    "    c_train_score = c_lr.score(c_data[:test_frac], lr_target[:test_frac])\n",
    "    c_test_score = c_lr.score(c_data[test_frac:], lr_target[test_frac:])\n",
    "    e_train_score = e_lr.score(e_data[:test_frac], lr_target[:test_frac])\n",
    "    e_test_score = e_lr.score(e_data[test_frac:], lr_target[test_frac:])\n",
    "\n",
    "    print(\n",
    "        f\"LogisticRegression Result -\\nRNN:\\ttest: {np.round(c_test_score,3)*100}%\\n\\ttrain: {np.round(c_train_score,3)*100}%\\nFFW:\\ttest: {np.round(e_test_score,3)*100}%\\n\\ttrain: {np.round(e_train_score,3)*100}%\")\n",
    "    json.dump({\"RNN\": {\"test\": c_test_score, \"train\": c_train_score}, \"FFW\": {\n",
    "        \"test\": e_test_score, \"train\": e_train_score}}, open(model_dir + \"LR_scores.json\", \"w\"))\n",
    "\n",
    "    c_tsne = TSNE(2)\n",
    "    e_tsne = TSNE(2)\n",
    "\n",
    "    tsne_spk = set(np.random.permutation(list(set(lr_target)))\n",
    "                   [:int(tsne_spk_frac*len(set(lr_target)))])\n",
    "\n",
    "    print(\"tsne_spk\", tsne_spk)\n",
    "\n",
    "    print(\"Computing t-SNE for\", len(tsne_spk), \"speakers.\")\n",
    "\n",
    "    tsne_ii = np.array([i for i, j in enumerate(lr_target) if j in tsne_spk])\n",
    "\n",
    "    print(\"tsne_ii:\", tsne_ii.shape)\n",
    "    print(\"c_data:\", c_data.shape)\n",
    "    print(\"c_data[tsne_ii]:\", c_data[tsne_ii].shape)\n",
    "    # Segmentation fault h√§r\n",
    "    c_embedding = c_tsne.fit_transform(c_data[tsne_ii])\n",
    "    e_embedding = e_tsne.fit_transform(e_data[tsne_ii])\n",
    "    tsne_targ = lr_target[tsne_ii]\n",
    "    print(\"tsn-target\", tsne_targ)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(5, 10))\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    for c in set(tsne_targ):\n",
    "        ii = np.where(tsne_targ == c)[0]\n",
    "        cc = c_embedding[ii]\n",
    "        ee = e_embedding[ii]\n",
    "        ax[0].scatter(cc[:, 0], cc[:, 1], s=.01, alpha=1)\n",
    "        ax[1].scatter(ee[:, 0], ee[:, 1], s=.01, alpha=1)\n",
    "        X.append(cc[:, 0])\n",
    "        y.append(cc[:, 1])\n",
    "        labels.append(c)\n",
    "    ax[0].set_title(\"RNN t-sne\")\n",
    "    ax[1].set_title(\"FFW t-sne\")\n",
    "\n",
    "    plt.savefig(model_dir + \"tsne_embedding.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"Computing Silhouette Coefficient score: \")\n",
    "    # X = np.array(X)\n",
    "    # y = np.array(y)\n",
    "    # labels = np.array(labels)\n",
    "    print(\"c_embedding: \", c_embedding.shape, type(c_embedding))\n",
    "    print(\"tsne_targ: \", tsne_targ.shape, type(tsne_targ))\n",
    "    # print(y.shape)\n",
    "    # new_x = np.vstack((X,y))\n",
    "    # print(c_embedding)\n",
    "    sc_score = metrics.silhouette_score(c_embedding, tsne_targ, metric='euclidean')\n",
    "    print(sc_score)\n",
    "\n",
    "    print(\"Computing Kolmogorov-Smirnov test: \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
